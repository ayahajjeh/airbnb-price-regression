# -*- coding: utf-8 -*-
"""Airbnb Price Regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JYZSKF03rsXeilsIjoFlL0pw8Wax_tSE

#Airbnb Price Regression Project
"""

import pandas as pd

train = pd.read_csv("/train.csv.zip")
test = pd.read_csv("/test.csv")

#to understand the general shape of the train and test data, and what type of feature data we have
print(train.shape)
print(test.shape)

print(train.columns)
print(test.columns)

train.head()

train.iloc[5]

train.iloc[7]

train.iloc[8]

# Commented out IPython magic to ensure Python compatibility.
#to understand specific features
import matplotlib.pyplot as plt
# %matplotlib inline

plt.rcParams["figure.autolayout"] = True

#how the number of review relate to the price
line1, = plt.plot(train['number_of_reviews'], train['price'], label = "price vs number_of_reviews")
#plt.hist(train['number_of_reviews'], alpha=0.5, density=True, label=train['price'])

plt.legend()
plt.show()

#how the number of minimum nights relate to the price
line1, = plt.plot(train['minimum_nights'], train['price'], label = "price vs minimum_nights")

#plt.hist(train['minimum_nights'], alpha=0.5, density=True, label=train['price'])

plt.legend()
plt.show()

#how the number_of_reviews_ltm relate to the price
line1, = plt.plot(train['number_of_reviews_ltm'], train['price'], label = "price vs number_of_reviews_ltm")

plt.legend()
plt.show()

#how the calculated_host_listings_count relate to the price
line1, = plt.plot(train['calculated_host_listings_count'], train['price'], label = "price vs calculated_host_listings_count")

plt.legend()
plt.show()

#how the availability_365 relate to the price
line1, = plt.plot(train['availability_365'], train['price'], label = "price vs availability_365")

plt.legend()
plt.show()

#how the reviews_per_month relate to the price
line1, = plt.plot(train['reviews_per_month'], train['price'], label = "price vs reviews_per_month")

plt.legend()
plt.show()

#how the latitude relate to the price
line1, = plt.plot(train['latitude'], train['price'], label = "price vs latitude")

plt.legend()
plt.show()

#how the longitude relate to the price
line1, = plt.plot(train['longitude'], train['price'], label = "price vs longitude")

plt.legend()
plt.show()

#try out model #1
from sklearn.ensemble import RandomForestClassifier

features = ["reviews_per_month", "calculated_host_listings_count", "number_of_reviews_ltm", "minimum_nights", "number_of_reviews"]
X = train[features]
y = train['price']
clf = RandomForestClassifier(max_depth=5, random_state=27)
clf.fit(X,y)
X_test = test[features]
pred_y = clf.predict(X_test)
pred_y

submission_data = {'id':test['id'], 'price':pred_y}
submission_df = pd.DataFrame(submission_data)
submission_df.head()

submission_df.to_csv("my_submission1.csv", index=False)

#try out model #2
from sklearn.ensemble import RandomForestClassifier

features = ["reviews_per_month", "calculated_host_listings_count", "number_of_reviews_ltm", "number_of_reviews"]
X = train[features]
y = train['price']
clf = RandomForestClassifier(max_depth=5, random_state=27)
clf.fit(X,y)
X_test = test[features]
pred_y = clf.predict(X_test)
pred_y

submission_data = {'id':test['id'], 'price':pred_y}
submission_df = pd.DataFrame(submission_data)
submission_df.head()

submission_df.to_csv("my_submission2.csv", index=False)

#try out model #3
from sklearn.ensemble import RandomForestClassifier

features = ["calculated_host_listings_count", "number_of_reviews_ltm", "minimum_nights", "number_of_reviews"]
X = train[features]
y = train['price']
clf = RandomForestClassifier(max_depth=5, random_state=27)
clf.fit(X,y)
X_test = test[features]
pred_y = clf.predict(X_test)
pred_y

submission_data = {'id':test['id'], 'price':pred_y}
submission_df = pd.DataFrame(submission_data)
submission_df.head()

submission_df.to_csv("my_submission3.csv", index=False)

#let's try to understand more features
#let's begin by examining the relation between the neighborhood group and the price

brooklyn = train[train['neighbourhood_group'] == 'Brooklyn']
manhattan = train[train['neighbourhood_group'] == 'Manhattan']
queens = train[train['neighbourhood_group'] == 'Queens']
bronx = train[train['neighbourhood_group'] == 'Bronx']
staten_island = train[train['neighbourhood_group'] == 'Staten Island']

neighborhoods = [brooklyn, manhattan, queens, bronx, staten_island]
labels = ["Brooklyn", "Manhattan", "Queens", "Bronx", "Staten Island"]

for neighborhood, label in zip(neighborhoods, labels):
  plt.hist(neighborhood['price'], alpha=0.2, density=True, label=label)

plt.legend()
plt.show()

#from the plot below, we realize that there isn't a fair distribution amongst price ranges
#there is barely any price data above 500, while the vast majority of price data points lie below 500
#we might have to reexamine and reweight our data

#let's try to understand the distribution of our data as a whole to examine if we need to reweight the training data
plt.hist(train['price'], alpha=0.2, density=True, label=label)

#as we can see in the graph below, the vast majority of data points lie between 0 and 250

#let's reweight our data to reduce the number of data points we have for prices between 0 and 250
train_reweighted = train.groupby('price', group_keys=False).apply(lambda x: train.sample(40, random_state=27))
train_reweighted.shape

plt.hist(train_reweighted['price'], alpha=0.2, density=True, label=label)

#try out model #4
from sklearn.ensemble import RandomForestClassifier

features = ["reviews_per_month", "calculated_host_listings_count", "number_of_reviews_ltm", "minimum_nights", "number_of_reviews"]
X = train_reweighted[features]
y = train_reweighted['price']
clf = RandomForestClassifier(max_depth=5, random_state=27)
clf.fit(X,y)
X_test = test[features]
pred_y = clf.predict(X_test)
pred_y

submission_data = {'id':test['id'], 'price':pred_y}
submission_df = pd.DataFrame(submission_data)
submission_df.head()

submission_df.to_csv("my_submission4.csv", index=False)

#let's examine the relation between the reweighted train data and the neighborhood group
brooklyn = train_reweighted[train_reweighted['neighbourhood_group'] == 'Brooklyn']
manhattan = train_reweighted[train_reweighted['neighbourhood_group'] == 'Manhattan']
queens = train_reweighted[train_reweighted['neighbourhood_group'] == 'Queens']
bronx = train_reweighted[train_reweighted['neighbourhood_group'] == 'Bronx']
staten_island = train_reweighted[train_reweighted['neighbourhood_group'] == 'Staten Island']

neighborhoods = [brooklyn, manhattan, queens, bronx, staten_island]
labels = ["Brooklyn", "Manhattan", "Queens", "Bronx", "Staten Island"]

for neighborhood, label in zip(neighborhoods, labels):
  plt.hist(neighborhood['price'], alpha=0.2, density=True, label=label)

plt.legend()
plt.show()

#let's have a closer look at the number of data points from each neighborhood group in both the training set and reweighted training set
from collections import Counter

c = Counter(train['neighbourhood_group'])
print(c)
c = Counter(train_reweighted['neighbourhood_group'])
print(c)

#try out model #5
#let's convert the neighborhood group column into integers and add the neighborhood group as a feature to our model
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder

features = ["neighbourhood_group", "reviews_per_month", "calculated_host_listings_count", "number_of_reviews_ltm", "minimum_nights", "number_of_reviews"]
X = train[features]
y = train['price']

# Create an instance of LabelEncoder
le = LabelEncoder()

# Fit and transform the Gender column
X['neighbourhood_group'] = le.fit_transform(X['neighbourhood_group'])

clf = RandomForestClassifier(max_depth=5, random_state=27)
clf.fit(X,y)
X_test = test[features]
X_test['neighbourhood_group'] = le.fit_transform(X_test['neighbourhood_group'])
pred_y = clf.predict(X_test)
pred_y

submission_data = {'id':test['id'], 'price':pred_y}
submission_df = pd.DataFrame(submission_data)
submission_df.head()

submission_df.to_csv("my_submission5.csv", index=False)

#try out model #6
#let's convert the neighborhood group column and the room type column into integers and add the neighborhood group as a feature to our model
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder

features = ["neighbourhood_group", "room_type", "reviews_per_month", "calculated_host_listings_count", "number_of_reviews_ltm", "minimum_nights", "number_of_reviews"]
X = train[features]
y = train['price']

# Create an instance of LabelEncoder
le = LabelEncoder()

# Fit and transform the Gender column
X['neighbourhood_group'] = le.fit_transform(X['neighbourhood_group'])
X['room_type'] = le.fit_transform(X['room_type'])

clf = RandomForestClassifier(max_depth=5, random_state=27)
clf.fit(X,y)
X_test = test[features]
X_test['neighbourhood_group'] = le.fit_transform(X_test['neighbourhood_group'])
X_test['room_type'] = le.fit_transform(X_test['room_type'])
pred_y = clf.predict(X_test)
pred_y

submission_data = {'id':test['id'], 'price':pred_y}
submission_df = pd.DataFrame(submission_data)
submission_df.head()

submission_df.to_csv("my_submission6.csv", index=False)